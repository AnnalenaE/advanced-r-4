---
title: "A linear regression in R"
author: "Maximilian Pfundstein, Annalena Erhard, Ruben Munoz"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true

vignette: >
  %\VignetteIndexEntry{A linear regression in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE
)
```
```{r, include = FALSE}
library(ggplot2)
library(linear.regression)
```


## Introduction

This package uses a linear regression model. It uses linear algebra to give a linear regresion model functionality when given a formula and a dataframe to work with. for the following examples the dataset `iris` will be used.

## Usage Methods

```{r echo=TRUE, fig.show='hold'}
linreg_mod = linreg$new(Petal.Length~Sepal.Width+Sepal.Length, data=iris)
```

### print() 

A method call  that gives back the formula along with the coeficients.
```{r, fig.show='hold'}
linreg_mod$print()
```

### plot() 

This one method call returns two plots containning the residuals in relation to the fitted values. the first one gives the Residuals vs Fitted, while the seccond one gives the Scale - Location.
```{r}
linreg_mod$plot()
```

### resid()
A method to call on the residuals

$$\hat{e} = y - \hat{y} = y - X\hat{\beta}$$
```{r, fig.show='hold', fig.align='center'}
head(linreg_mod$resid())
```

### pred() 
A method call to get the predicted values $\hat{y}$.
```{r, fig.show='hold'}
head(linreg_mod$pred())
```

### coef() 

A method call to get the coefficients as a named vector.

$$\hat{\beta} = (X^TX)^{-1}X^Ty$$

```{r, fig.show='hold'}
linreg_mod$coef()
```

### summary()
This returns a printout presenting the coefficients with their standard error, t-value and p-value as well as the estimate of $\hat{\sigma}$ along with the degrees of freedom in the model.

```{r, fig.show='hold'}
linreg_mod$summary()
```

## References 

[Matrix decompositions for regression analysis](https://www.stat.wisc.edu/courses/st849-bates/lectures/Orthogonal.pdf)

 [Some	Notes	on	Least	Squares, QR-factorization, SVD and	Fitting](http://staff.www.ltu.se/~jove/courses/c0002m/least_squares.pdf)
